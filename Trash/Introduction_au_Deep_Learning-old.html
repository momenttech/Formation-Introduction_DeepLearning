<html>
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Formation au Deep-Learning - Web site</title>
		<link rel="stylesheet" href="../assets/css/highlight.min.css">
		<link rel="stylesheet" href="../assets/css/bootstrap.min.css">
		<link rel="stylesheet" href="../assets/css/tipuesearch.css">
		<link rel="stylesheet" href="../assets/css/main.css">
	</head>
	<body>
		<header class="navbar navbar-default navbar-fixed-top">
			<div class="container-fluid">
				<div class="navbar-header">
					<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1">
						<span class="sr-only">Toggle navigation</span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
						<span class="icon-bar"></span>
					</button>
					<a class="navbar-brand" href="../">Web site</a> <p class="navbar-text hidden-xs">Formation au Deep-Learning</p>
				</div>

				<div class="collapse navbar-collapse" id="navbar-collapse-1">
					<form action="../search.html" class="navbar-form navbar-right" role="search">
						<div class="form-group">
							<input type="text" name="q" id="tipue_search_input" autocomplete="off" required class="form-control" placeholder="Search">
						</div>
					</form>
					<ul class="nav navbar-nav navbar-right">
						<li><a href="../Trash/Introduction_au_Deep_Learning-old-slideshow.html" target="_blank">View as slideshow</a></li>
						<!--li><a href="../Trash/Introduction_au_Deep_Learning-old-raw.html">View Markdown</a></li-->
					</ul>
				</div>
			</div>
		</header>

		<!--
<div class="toc">
<p class="lead">Table of contents:</p>
<p class="toc-1">
<a href="#formation-au-deep-learning">Formation au Deep-Learning</a>
</p>
<p class="toc-2">
<a href="#sommaire">Sommaire</a>
</p>
<p class="toc-2">
<a href="#les-matrices-quelques-rappels-">Les matrices : quelques rappels !</a>
</p>
<p class="toc-3">
<a href="#l-39-addition-de-matrice">L&amp;#39;addition de matrice</a>
</p>
<p class="toc-3">
<a href="#le-produit-matriciel">Le produit matriciel</a>
</p>
<p class="toc-2">
<a href="#r-seau-de-neurones">Réseau de neurones</a>
</p>
<p class="toc-3">
<a href="#le-r-seau-fully-connected-">Le réseau *fully connected*</a>
</p>
<p class="toc-2">
<a href="#droites-de-r-gression">Droites de régression</a>
</p>
<p class="toc-3">
<a href="#r-gression-lin-aire">Régression linéaire</a>
</p>
<p class="toc-3">
<a href="#la-fonction-d-39-activation">La fonction d&amp;#39;activation</a>
</p>
<p class="toc-2">
<a href="#listes-de-matrices">Listes de matrices</a>
</p>
<p class="toc-3">
<a href="#matrice-d-finition">Matrice : définition</a>
</p>
<p class="toc-2">
<a href="#calculs-par-cpu-gpu-tpu">Calculs par CPU / GPU / TPU</a>
</p>
<p class="toc-3">
<a href="#cpu-versus-gpu">CPU versus GPU</a>
</p>
<p class="toc-3">
<a href="#tpu-k-sako-">TPU ? Késako ?</a>
</p>
<p class="toc-2">
<a href="#calcul-d-39-erreur">Calcul d&amp;#39;erreur</a>
</p>
<p class="toc-3">
<a href="#notion-d-39-erreur">Notion d&amp;#39;erreur</a>
</p>
<p class="toc-3">
<a href="#le-batch">Le batch</a>
</p>
<p class="toc-3">
<a href="#le-minimum-local">Le minimum local</a>
</p>
<p class="toc-3">
<a href="#le-learning-rate-">Le *learning rate*</a>
</p>
<p class="toc-3">
<a href="#le-vanishing-gradients-">Le *vanishing gradients*</a>
</p>
<p class="toc-3">
<a href="#l-39-overfitting-">L&amp;#39;*overfitting*</a>
</p>
</div>
-->

		<div class="container">
			<div class="row">
				<nav id="sidebar" class="col-lg-2 col-sm-3">
					<ul class="nav nav-pills nav-stacked">
					</ul>
					<!--
Available versions:<br>
raw<br>
->Trash/Introduction_au_Deep_Learning-old-raw.html<br>
slideshow<br>
->Trash/Introduction_au_Deep_Learning-old-slideshow.html<br>
default<br>
->Trash/Introduction_au_Deep_Learning-old.html<br>
<br>
Document informations:<br>
Trash/Introduction_au_Deep_Learning-old.md<br><br>
active
-->
				</nav>
				<header>
					<div class="entry-meta text-right">

					</div>
				</header>
				<article id="content" class="col-lg-10 col-sm-9">
					<h1 id="formation-au-deep-learning">Formation au Deep-Learning</h1>
<h2 id="sommaire">Sommaire</h2>
<ul>
<li>Réseau de neurones</li>
<li>Droites de régression</li>
<li>Listes de matrices</li>
<li>Calcul d’erreur</li>
</ul>
<h2 id="les-matrices-quelques-rappels-">Les matrices : quelques rappels !</h2>
<h3 id="l-addition-de-matrice">L&#39;addition de matrice</h3>
<h4 id="g-n-ralit-s-">Généralités :</h4>
<ul>
<li>L&#39;addition des matrices est définie pour deux matrices de même type.</li>
<li>La somme de deux matrices de type (m, n), est obtenue en additionnant les éléments correspondants.</li>
</ul>
<h4 id="exemple-avec-">Exemple avec :</h4>
<p>[
\begin{Bmatrix}
   A_{1}  \
   A_{2}
\end{Bmatrix}
] + [
\begin{Bmatrix}
   B_{1}  \
   B_{2}
\end{Bmatrix}
]</p>
<h3 id="le-produit-matriciel">Le produit matriciel</h3>
<h4 id="g-n-ralit-s-">Généralités :</h4>
<ul>
<li>La multiplication des matrices n&#39;est pas commutative, c&#39;est-à-dire que AB n&#39;est pas égal à BA.</li>
</ul>
<p>À l’avenir, nous aurons seulement besoin de connaitre le produit d’une matrice de type (1,2) et d’une matrice de type (2,2).</p>
<h4 id="exemple-avec-">Exemple avec :</h4>
<p>[
\begin{Bmatrix}
   A_{1}  \
   A_{2}
\end{Bmatrix}
] + [
\begin{Bmatrix}
   B_{1} &amp;&amp; B_{1,2}  \
   B_{2,1} &amp;&amp; B_{2,2}
\end{Bmatrix}
]</p>
<h2 id="r-seau-de-neurones">Réseau de neurones</h2>
<h3 id="le-r-seau-fully-connected">Le réseau <em>fully connected</em></h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Le neurone formel est conçu comme un automate doté d&#39;une fonction de transfert qui transforme ses entrées en sortie selon des règles précises. Ces neurones sont par ailleurs associés en réseaux dont la topologie des connexions est variable : réseaux proactifs, récurrents, etc..</li>
</ul>
<p><img src="pictures/nerve-cell.jpg" width="500" height="350" align="" ></p>
<ul>
<li>Un réseau de neurones est considéré « fully connected » lorsque toute entrée est relié par une arête appelé « poids » et représenté par «  » à l’intégralité des neurones présents dans les couches cachées.</li>
</ul>
<p><img src="pictures/neurons-network.jpg" width="500" height="350" align="" ></p>
<h4 id="repr-sentation-graphique-">Représentation graphique :</h4>
<p><img src="" alt="Schema"></p>
<p>[ ! ] Les couches cachées sont appelé zone de « pré-activation » et l’ensemble des output zone d’ « activation ».</p>
<h4 id="d-finition-d-un-biais-">Définition d&#39;un biais :</h4>
<ul>
<li>Le biais est l&#39;erreur provenant d’hypothèses erronées dans l&#39;algorithme d&#39;apprentissage. Un biais élevé peut être lié à un algorithme qui manque de relations pertinentes entre les données en entrée et les sorties prévues (sous-apprentissage).</li>
</ul>
<h4 id="d-finition-d-une-fonction-d-activation-">Définition d’une fonction d’activation :</h4>
<ul>
<li>La fonction d’activation (ou fonction de seuillage, ou encore fonction de transfert) sert à introduire une non-linéarité dans le fonctionnement du neurone.</li>
<li>Les fonctions de seuillage présentent généralement trois intervalles :<ul>
<li>en dessous du seuil, le neurone est non-actif</li>
<li>aux alentours du seuil, une phase de transition</li>
<li>au-dessus du seuil, le neurone est actif</li>
</ul>
</li>
</ul>
<h4 id="calcul-de-la-valeur-d-un-neurone-">Calcul de la valeur d&#39;un neurone :</h4>
<h2 id="droites-de-r-gression">Droites de régression</h2>
<h3 id="r-gression-lin-aire">Régression linéaire</h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Désigne un modèle dans lesquels est la médiane conditionnelle de « y » sachant « x ».</li>
<li>Le modèle de régression linéaire est souvent estimé par la méthode des moindres carrés mais il existe aussi de nombreuses autres méthodes pour estimer ce modèle.</li>
</ul>
<h4 id="repr-sentation-graphique-du-r-seau-pr-c-dent-">Représentation graphique du réseau précèdent :</h4>
<p><img src="pictures/playgrnd-reseau-simple.jpg" alt="Playground 2 neurones"></p>
<p>Ce schéma représente ainsi la fonction d’activation</p>
<h3 id="la-fonction-d-activation">La fonction d&#39;activation</h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>La fonction d’activation est une fonction mathématique appliquée à un signal en sortie d&#39;un neurone artificiel. Soit dans notre cas à la droite de régression linéaire.</li>
</ul>
<h4 id="graphiquement-">Graphiquement :</h4>
<h4 id="cas-pratique-">Cas pratique :</h4>
<ul>
<li>playground.tensorflow.org</li>
</ul>
<p><img src="pictures/playgrnd-tf.jpg" alt="Aperçu du playground tensorflow"></p>
<h2 id="listes-de-matrices">Listes de matrices</h2>
<h3 id="matrice-d-finition">Matrice : définition</h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Les matrices sont des tableaux de nombres qui servent à interpréter en termes calculatoires et donc opérationnels les résultats théoriques de l&#39;algèbre</li>
</ul>
<p><img src="pictures/matrix.jpg" alt="Matrice"></p>
<h4 id="prenons-pour-exemple-cette-image-">Prenons pour exemple, cette image :</h4>
<p><img src="pictures/dog.jpg" alt="Image exemple"></p>
<h2 id="calculs-par-cpu-gpu-tpu">Calculs par CPU / GPU / TPU</h2>
<h3 id="cpu-versus-gpu">CPU versus GPU</h3>
<h4 id="le-facteur-nombre-de-c-urs-">Le facteur nombre de cœurs :</h4>
<p><img src="pictures/cpu-vs-gpu.jpg" alt="Comparaison CPU - GPU"></p>
<ul>
<li>Avantages :<ul>
<li>Accélération via GPU des applications</li>
</ul>
</li>
</ul>
<p><img src="pictures/accelleration-gpu.jpg" alt="Schema CPU - GPU"></p>
<h4 id="d-monstration-">Démonstration :</h4>
<p><img src="pictures/cpu.gif" alt="Compa CPU - GPU">
<img src="pictures/gpu.gif" alt="Compa CPU - GPU"></p>
<p><a href="https://www.youtube.com/watch?v=-P28LKWTzrI">https://www.youtube.com/watch?v=-P28LKWTzrI</a></p>
<h3 id="tpu-k-sako-">TPU ? Késako ?</h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Le TPU (Tensor Processor Unit) est un module hardware dédié spécifiquement aux applications de Machine Learning</li>
</ul>
<p><img src="pictures/tpu.jpg" alt="TPU"></p>
<h2 id="calcul-d-erreur">Calcul d&#39;erreur</h2>
<h3 id="notion-d-erreur">Notion d&#39;erreur</h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>A chaque itération, l&#39;algorithme va calculer un indicateur de performance globale (l&#39;erreur qu&#39;il commet) en comparant la sortie attendue et la sortie prédite.</li>
</ul>
<p><img src="pictures/un-plus-un.jpg" alt="1+1"></p>
<h3 id="le-batch">Le batch</h3>
<h4 id="d-finition-">Définition :</h4>
<h3 id="le-minimum-local">Le minimum local</h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Le minimum local est point dans une zone où le système établit qu’il ne peut semble pense avoir obtenu la meilleure précision mais ne l’est effectivement pas sur la courbe de précision de classification.</li>
</ul>
<p><img src="pictures/minim-local.jpg" alt="Minimum local"></p>
<h3 id="le-learning-rate">Le <em>learning rate</em></h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Représente la taille du « pas » en avant effectuer par le système pour atteindre le point d’apprentissage le plus efficient</li>
</ul>
<p><img src="pictures/LR1.jpg" alt="TPU">
<img src="pictures/LR2.jpg" alt="TPU"></p>
<h3 id="le-vanishing-gradients">Le <em>vanishing gradients</em></h3>
<p><img src="pictures/vanish.png" alt="TPU"></p>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>Le vanishing gradients est une perte (ou fuite) de gradient, affectant les neurones plus profond et unités de saturations dans un réseau profond.</li>
</ul>
<p><img src="pictures/long-network.jpg" alt="TPU"></p>
<h3 id="l-overfitting">L&#39;<em>overfitting</em></h3>
<h4 id="d-finition-">Définition :</h4>
<ul>
<li>L’overfitting (ou surapprentissage) est une étape où le système est arrivé à reconnaitre quasi-seulement les images sur lesquelles il a été entrainé et une variation de lumière ou de milieu peut l’induire à ne pas reconnaitre l’objet.</li>
</ul>
<p><img src="pictures/overfitting.jpg" alt="TPU"></p>

				</article>
			</div>
		</div>

		<footer><a href="../site-index.html">Pages index</a>
</footer>

		<script src="../assets/js/jquery.js"></script>
		<script src="../assets/js/bootstrap.min.js"></script>
		<script src="../assets/js/highlight.min.js"></script>
		<script src="../assets/js/tipuesearch_set.js"></script>
		<script src="../assets/js/tipuesearch.min.js"></script>
		<script>
			$(function() {
				hljs.initHighlightingOnLoad();
				$('#tipue_search_input').tipuesearch({
					mode: 'json',
					contentLocation: '../index.json'
				});
			});
		</script>
		
		<!-- Generated by Vegetables from 'Trash/Introduction_au_Deep_Learning-old.md' with format 'default' - '2018-6-15 17:39:27' -->
	</body>
</html>
